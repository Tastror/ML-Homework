{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting Detect 手写识别\n",
    "\n",
    "Demo1 Homework\n",
    "\n",
    "Tastror\n",
    "\n",
    "## 一、开发环境\n",
    "\n",
    "gpu 相关\n",
    "\n",
    "- 显卡为 NVIDIA 公司产品，在 帮助 - 系统信息 中查看 GPU 支持的最高 CUDA 版本为 11.7。\n",
    "- 在 pytorch 官网（2023/3/21）中支持的 CUDA 版本为 11.7 或 11.8\n",
    "\n",
    "pytorch 相关\n",
    "\n",
    "```shell\n",
    "conda create --name py311_torch python=3.11\n",
    "conda activate py311_torch\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117  # in 2023/3/21, it is 2.0.0\n",
    "```\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| pytorch 版本 | Python 版本 | cuDNN | CUDA | Windows 版本 |\n",
    "| ---- | ---- | ---- | ---- | ---- |\n",
    "| pytorch-2.0.0 | Any (3.11 is used) | Any (8.8.1 is used) | 11.7 | 11 |\n",
    "\n",
    "</div>\n",
    "\n",
    "为了后面的画图方便，我们同时安装 matplotlib。\n",
    "\n",
    "```shell\n",
    "pip install matplotlib  # in 2023/3/21, it is 3.7.1\n",
    "```\n",
    "\n",
    "以及安装 Demo1 中会用到的库\n",
    "\n",
    "```shell\n",
    "pip install scipy  # in 2023/3/21, it is 1.10.1\n",
    "pip install opencv-contrib-python  # in 2023/3/21, it is 4.7.0.72\n",
    "pip install kornia  # in 2023/3/21, it is 0.6.10\n",
    "```\n",
    "\n",
    "接着查看一下 GPU 是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可用，说明环境搭建成功，并且尝试运行 Demo1 中的代码，没有问题。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、分析与模型搭建\n",
    "\n",
    "首先直接运行，看看结果。\n",
    "\n",
    "运行的最后几行输出如图。\n",
    "\n",
    "```plaintext\n",
    "Start Train\n",
    "Epoch 300/300:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 92/93 [00:00<00:00, 259.91it/s, acc=1, loss=3.25e-7]Start test\n",
    "Epoch 300/300: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:00<00:00, 260.92it/s, acc=1, loss=3.25e-7] \n",
    "Epoch 300/300: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 497.29it/s, acc=0.726]\n",
    "```\n",
    "\n",
    "训练集上的准确率为 100%，而测试集上的数据只有 72.6%，很明显过拟合了。\n",
    "\n",
    "我们从源数据和模型两个方面进行分析。\n",
    "\n",
    "### （一）源数据\n",
    "\n",
    "对于 Demo1 数据集，其有两部分组成：train 和 test，使用 scipy 读取后可用看到其中的具体数据长度。\n",
    "\n",
    "```python\n",
    "self.data = scio.loadmat(path)\n",
    "self.data = self.data['train'] if train else self.data['test']\n",
    "self.shape = np.shape(self.data)\n",
    "self.data_shape = self.shape[:2]\n",
    "self.image_shape = self.shape[2:]\n",
    "self.length = self.data_shape[0] * self.data_shape[1]\n",
    "\n",
    "print('length of dataset is', self.length, end=\", \")\n",
    "print('shape of dataset is', self.data_shape, end=\", \")\n",
    "print('shape of image is', self.image_shape)\n",
    "```\n",
    "\n",
    "输出为\n",
    "\n",
    "```plaintext\n",
    "length of dataset is 3000, shape of dataset is (200, 15), shape of image is (28, 28)  # training dataset\n",
    "length of dataset is 1000, shape of dataset is (200, 5), shape of image is (28, 28)  # test dataset\n",
    "```\n",
    "\n",
    "也就是训练集有 200 个标签，每个标签下有 15 张图片。图片的大小为 28 * 28，和手写数字类似。\n",
    "\n",
    "很明显，这个图片的数据量是很小的（MNIST 的训练集有 60,000 张，也就是每个标签下有 6000 张图片），所以在训练之前，我们需要进行一下数据增强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "augment_type_num = 7\n",
    "\n",
    "def augment(image, augmentation_type, rand_source):\n",
    "\n",
    "    if augmentation_type == 0:\n",
    "        pass\n",
    "    elif augmentation_type == 1:\n",
    "        # 缩放并平移\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((24, 24), resample=Image.BILINEAR)\n",
    "        image = np.array(image)\n",
    "        image = np.pad(image, (2, 2), 'constant', constant_values=0)\n",
    "        if rand_source % 4 == 0:\n",
    "            image = np.roll(image, 5, axis=0)\n",
    "        elif rand_source % 4 == 1:\n",
    "            image = np.roll(image, -5, axis=0)\n",
    "        elif rand_source % 4 == 2:\n",
    "            image = np.roll(image, 5, axis=1)\n",
    "        else:\n",
    "            image = np.roll(image, -5, axis=1)\n",
    "    elif augmentation_type == 2:\n",
    "        # 缩放并平移\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((24, 24), resample=Image.BILINEAR)\n",
    "        image = np.array(image)\n",
    "        image = np.pad(image, (2, 2), 'constant', constant_values=0)\n",
    "        if rand_source % 4 == 0:\n",
    "            image = np.roll(image, -5, axis=0)\n",
    "            image = np.roll(image, -5, axis=1)\n",
    "        elif rand_source % 4 == 1:\n",
    "            image = np.roll(image, 5, axis=0)\n",
    "            image = np.roll(image, 5, axis=1)\n",
    "        elif rand_source % 4 == 2:\n",
    "            image = np.roll(image, 5, axis=0)\n",
    "            image = np.roll(image, -5, axis=1)\n",
    "        else:\n",
    "            image = np.roll(image, -5, axis=0)\n",
    "            image = np.roll(image, 5, axis=1)\n",
    "    elif augmentation_type == 3:\n",
    "        # 旋转操作\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.rotate(10)\n",
    "        image = np.array(image)\n",
    "    elif augmentation_type == 4:\n",
    "        # 旋转操作\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.rotate(-10)\n",
    "        image = np.array(image)\n",
    "    elif augmentation_type == 5:\n",
    "        # 缩放操作\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((24, 24), resample=Image.BILINEAR)\n",
    "        image = np.array(image)\n",
    "        image = np.pad(image, (2, 2), 'constant', constant_values=0)\n",
    "    elif augmentation_type == 6:\n",
    "        # 缩放操作\n",
    "        image = Image.fromarray(image)\n",
    "        image = image.resize((32, 32), resample=Image.BILINEAR)\n",
    "        image = np.array(image)\n",
    "        image = image[2:30, 2:30]\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以此增强后，数据变为原来的 7 倍，虽然还是不太够，但是已能初步缓解数据不足的问题。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （二）模型\n",
    "\n",
    "这里我选择添加一层卷积层，并且由于测试集和训练集的准确率相差太大，所以我添加了 dropout。\n",
    "\n",
    "```plaintext\n",
    "Epoch 49/50, Loss: 0.0190, Acc: 95.7554\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 657/657 [00:03<00:00, 173.10it/s] \n",
    "Epoch 50/50, Loss: 0.0368, Acc: 95.8160\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 312.85it/s]\n",
    "Test Accuracy: 0.8780\n",
    "```\n",
    "\n",
    "测试集上的准确率为 87.8%，比原来高。\n",
    "\n",
    "经过多次测试，目前表现最优的模型能达到测试集上 92% 的准确率。代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, label_num: int = 200):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.lr = 0.001\n",
    "        self.weight_decay = 0\n",
    "\n",
    "        self.conv_features_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.conv_features_2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.conv_features_3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "\n",
    "        self.conv_features_4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, label_num),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_features_1(x)\n",
    "        x = self.conv_features_2(x)\n",
    "        x = self.conv_features_3(x)\n",
    "        x = self.conv_features_4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （三）其他修缮\n",
    "\n",
    "#### 1：数据要足够多\n",
    "目前数据增强的内容是够用的。如果欠缺还需进一步增强，如进行一定程度的扭曲拉伸等。  \n",
    "无数据增强和有数据增强的默认模型，75% -> 83%\n",
    "\n",
    "#### 2：深度要足够描述特征\n",
    "最开始是目前采用的是四层卷积+池化；新的模型采用了（卷积+卷积+池化）这样的结构一共三层，然后是三个线性层。  \n",
    "模型 demo-3 和 demo-4 的区别，91% -> 92.5%\n",
    "\n",
    "#### 2：Dropout 的位置对模型的收敛速度影响巨大\n",
    "一种是 Conv2D -> Dropout -> BatchNorm -> ReLU；  \n",
    "另一种是 Conv2D -> BatchNorm -> ReLU -> Dropout。  \n",
    "这两种写法之间的主要区别在于 dropout（丢弃）和 Batch Normalization（批归一化）的顺序。  \n",
    "在第一种写法中，dropout 被应用于 Batch Normalization 前。因此，在使用 dropout 之后，特征图的方差和均值相比原来会产生不稳定的变化，并且 dropout 可能会丢弃对某些特征的有用贡献。  \n",
    "在第二种写法中，dropout 被放在 ReLU 激活函数之后，这意味着它被应用于激活后的特征图。在这种情况下，dropout 不会影响特征图的方差和均值，不容易丢弃对模型学习有用的信息。  \n",
    "因此，第二种写法通常更受欢迎，因为它可以更好地防止过拟合，而且对模型的训练和性能更有益。  \n",
    "无数据增强的 150 epoch 速训，模型 demo-3，第一种为 77%（主要是因为增长太慢），第二种为 87%\n",
    "\n",
    "#### 4：降低学习率\n",
    "学习率从 0.001 降低到了 0.0005，之前后期无法进步的学习就能够进行了。  \n",
    "最终我们降为了 0.0002\n",
    "```python\n",
    "# Adam\n",
    "self.lr = 0.0002\n",
    "self.weight_decay = 0.005\n",
    "``` \n",
    "模型 demo-4，400 epoch 内，92% -> 93%\n",
    "\n",
    "#### 5：使用 weight_decay 正则（或者使用 AdamW，自带 weight_decay）\n",
    "默认 Adam 的 weight_decay 是 0。若要进行 L2 正则化，可手动赋值为 0.001 等值。AdamW 默认参数值是 0.01。\n",
    "\n",
    "#### 6：重复数据\n",
    "对于数据中重复或类似字符相关的内容，在一一比对后，统计出它们一共有 5 组（4 组两两相似和 1 组 3 个相似）。  \n",
    "其准确率上限的平均情况为 97%。在去除后可以提升这 3% 的上限。\n",
    "\n",
    "```python\n",
    "redundant = [\n",
    "    (0, 81), (27, 39), (45, 195), (99, 114), (120, 121, 122)\n",
    "]\n",
    "```\n",
    "\n",
    "以上内容均为相似（前四个）或重复（最后一个）内容，将只保留第一个标签，其余映射到末尾（删除也可，这里采取的是映射，81->194, 39->196, 114->197, 121->198, 122->199）。\n",
    "\n",
    "\n",
    "最终代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, label_num: int = 200):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # Adam\n",
    "        self.lr = 0.0002\n",
    "        self.weight_decay = 0.005\n",
    "\n",
    "        self.conv_features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            # nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear'),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(3136, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(512, label_num),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在不同数据集下的测试结果为（epoch <= 400）\n",
    "\n",
    "| 数据集 | 准确率 |\n",
    "| --- | --- |\n",
    "| 训练集 | 99.69% |\n",
    "| 增强训练集（训练时使用） | 98.93% |\n",
    "| 测试集 | 95.05% |\n",
    "| 增强测试集 | 92.16% |\n",
    "\n",
    " ![inference gif](https://s2.loli.net/2023/03/31/ptNwU158ZIRarQe.png)  \n",
    "infer.py 展示\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
