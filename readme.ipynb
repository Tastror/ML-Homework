{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwriting Detect 手写识别\n",
    "\n",
    "Demo1 Homework\n",
    "\n",
    "Tastror\n",
    "\n",
    "## 一、开发环境\n",
    "\n",
    "gpu 相关\n",
    "\n",
    "- 显卡为 NVIDIA 公司产品，在 帮助 - 系统信息 中查看 GPU 支持的最高 CUDA 版本为 11.7。\n",
    "- 在 pytorch 官网（2023/3/21）中支持的 CUDA 版本为 11.7 或 11.8\n",
    "\n",
    "pytorch 相关\n",
    "\n",
    "```shell\n",
    "conda create --name py311_torch python=3.11\n",
    "conda activate py311_torch\n",
    "pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117  # in 2023/3/21, it is 2.0.0\n",
    "```\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "| pytorch 版本 | Python 版本 | cuDNN | CUDA | Windows 版本 |\n",
    "| ---- | ---- | ---- | ---- | ---- |\n",
    "| pytorch-2.0.0 | Any (3.11 is used) | Any (8.8.1 is used) | 11.7 | 11 |\n",
    "\n",
    "</div>\n",
    "\n",
    "为了后面的画图方便，我们同时安装 matplotlib。\n",
    "\n",
    "```shell\n",
    "pip install matplotlib  # in 2023/3/21, it is 3.7.1\n",
    "```\n",
    "\n",
    "以及安装 Demo1 中会用到的库\n",
    "\n",
    "```shell\n",
    "pip install scipy  # in 2023/3/21, it is 1.10.1\n",
    "pip install opencv-contrib-python  # in 2023/3/21, it is 4.7.0.72\n",
    "pip install kornia  # in 2023/3/21, it is 0.6.10\n",
    "```\n",
    "\n",
    "接着查看一下 GPU 是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可用，说明环境搭建成功，并且尝试运行 Demo1 中的代码，没有问题。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、样例测试与分析\n",
    "\n",
    "首先直接运行，看看结果。\n",
    "\n",
    "运行的最后几行输出如图。\n",
    "\n",
    "```plaintext\n",
    "Start Train\n",
    "Epoch 300/300:  99%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 92/93 [00:00<00:00, 259.91it/s, acc=1, loss=3.25e-7]Start test\n",
    "Epoch 300/300: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:00<00:00, 260.92it/s, acc=1, loss=3.25e-7] \n",
    "Epoch 300/300: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 497.29it/s, acc=0.726]\n",
    "```\n",
    "\n",
    "训练集上的准确率为 100%，而测试集上的数据只有 72.6%，很明显过拟合了。\n",
    "\n",
    "我们从源数据和模型两个方面进行分析。\n",
    "\n",
    "### （一）源数据\n",
    "\n",
    "对于 Demo1 数据集，其有两部分组成：train 和 test，使用 scipy 读取后可用看到其中的具体数据长度。\n",
    "\n",
    "```python\n",
    "self.data = scio.loadmat(path)\n",
    "self.data = self.data['train'] if train else self.data['test']\n",
    "self.shape = np.shape(self.data)\n",
    "self.data_shape = self.shape[:2]\n",
    "self.image_shape = self.shape[2:]\n",
    "self.length = self.data_shape[0] * self.data_shape[1]\n",
    "\n",
    "print('length of dataset is', self.length, end=\", \")\n",
    "print('shape of dataset is', self.data_shape, end=\", \")\n",
    "print('shape of image is', self.image_shape)\n",
    "```\n",
    "\n",
    "输出为\n",
    "\n",
    "```plaintext\n",
    "length of dataset is 3000, shape of dataset is (200, 15), shape of image is (28, 28)  # training dataset\n",
    "length of dataset is 1000, shape of dataset is (200, 5), shape of image is (28, 28)  # test dataset\n",
    "```\n",
    "\n",
    "也就是训练集有 200 个标签，每个标签下有 15 张图片。图片的大小为 28 * 28，和手写数字类似。\n",
    "\n",
    "很明显，这个图片的数据量是很小的（MNIST 的训练集有 60,000 张，也就是每个标签下有 6000 张图片），所以在训练之前，我们需要进行一下数据增强。\n",
    "\n",
    "```python\n",
    "# 反色预处理\n",
    "image = 255 - np.array(image)\n",
    "\n",
    "# 增强\n",
    "if augmentation_type == 0:\n",
    "    pass\n",
    "elif augmentation_type == 1:\n",
    "    if index % 2 == 0:\n",
    "        image = np.roll(image, 3, axis=0)  # 平移操作\n",
    "    else:\n",
    "        image = np.roll(image, -3, axis=0)  # 平移操作\n",
    "elif augmentation_type == 2:\n",
    "    if index % 2 == 0:\n",
    "        image = np.roll(image, 3, axis=1)  # 平移操作\n",
    "    else:\n",
    "        image = np.roll(image, -3, axis=1)  # 平移操作\n",
    "elif augmentation_type == 3:\n",
    "    # 旋转操作\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.rotate(10)\n",
    "    image = np.array(image)\n",
    "elif augmentation_type == 4:\n",
    "    # 旋转操作\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.rotate(-10)\n",
    "    image = np.array(image)\n",
    "elif augmentation_type == 5:\n",
    "    # 缩放操作\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((24, 24), resample=Image.BILINEAR)\n",
    "    image = np.array(image)\n",
    "    image = np.pad(image, (2, 2), 'constant', constant_values=0)\n",
    "elif augmentation_type == 6:\n",
    "    # 缩放操作\n",
    "    image = Image.fromarray(image)\n",
    "    image = image.resize((32, 32), resample=Image.BILINEAR)\n",
    "    image = np.array(image)\n",
    "    image = image[2:30, 2:30]\n",
    "```\n",
    "\n",
    "这里使用基本的平移与缩放进行增强（字符不能旋转），将数据量变为了原来的七倍。（具体代码见 dataloader.py）\n",
    "\n",
    "最终在 50 个 epoch 的训练下（损失函数已收敛），在**原模型**下的结果为\n",
    "\n",
    "```plaintext\n",
    "Epoch 49/50, Loss: 0.0219, Acc: 96.3887\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 657/657 [00:03<00:00, 165.15it/s] \n",
    "Epoch 50/50, Loss: 0.0198, Acc: 96.4500\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 271.03it/s]\n",
    "Test Accuracy: 0.7730\n",
    "```\n",
    "\n",
    "测试集上的准确率为 77.3%，比原来高。\n",
    "\n",
    "### （二）模型\n",
    "\n",
    "这里我选择添加一层卷积层，并且由于测试集和训练集的准确率相差太大，所以我添加了 dropout。\n",
    "\n",
    "```plaintext\n",
    "Epoch 49/50, Loss: 0.0190, Acc: 95.7554\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 657/657 [00:03<00:00, 173.10it/s] \n",
    "Epoch 50/50, Loss: 0.0368, Acc: 95.8160\n",
    "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 312.85it/s]\n",
    "Test Accuracy: 0.8380\n",
    "```\n",
    "\n",
    "测试集上的准确率为 83.8%，比原来高。\n",
    "\n",
    "经过多次测试，目前表现最优的模型能达到测试集上 90.9% 的准确率。代码如下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# 定义模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, label_num: int = 200):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_features_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.conv_features_2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.conv_features_3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "\n",
    "        self.conv_features_4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, label_num),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_features_1(x)\n",
    "        x = self.conv_features_2(x)\n",
    "        x = self.conv_features_3(x)\n",
    "        x = self.conv_features_4(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在不同数据集下的测试结果为（epoch = 196）\n",
    "\n",
    "| 数据集 | 准确率 |\n",
    "| --- | --- |\n",
    "| 训练集 | 98.37% |\n",
    "| 增强训练集（训练时使用） | 97.69% |\n",
    "| 测试集 | 91.00% |\n",
    "| 增强测试集 | 88.36% |\n",
    "\n",
    "这里的几层的 dropout 是延续前面测试三层卷积的 0.2 0.2 0.25 的 Dropout，它们起到了很好的防过拟合的作用（经测试，0.2 0.2 0.2 就没有这么好的效果了，容易过拟合）。\n",
    "\n",
    "因此这里的四层卷积使用了 0.2 0.2 0.25 0.25 的 Dropout，结果完全不会过拟合。（在增强数据集上）"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面使用了更多东西，让其效果达到了 95%。自己看去吧。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
